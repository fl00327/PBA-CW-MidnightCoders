natalB<-read.csv(DATASET_FILENAME)
View(natalB)
# Child_race deleted
natalB<-natalB[,-(4)]
# X deleted
natalB<-natalB[,-(1)]
# Source Year deleted
natalB<-natalB[,-(1)]
# father_race deleted
natalB<-natalB[,-(16)]
# record_weight deleted
natalB<-natalB[,-(17)]
#Converting the true falso to 1 and 0
natalB[,c("cigarette_use")] <- as.integer(as.logical(natalB$cigarette_use))
natalB[,c("alcohol_use")] <- as.integer(as.logical(natalB$alcohol_use))
natalB[,c("is_male")] <- as.integer(as.logical(natalB$is_male))
#pre-processing the data averaging the fields for the missing data
#Replacing na with the average mean of the column
natalB$mother_race = ifelse(is.na(natalB$mother_race), round(ave(natalB$mother_race, FUN = function(x) mean(x, na.rm = TRUE ))), natalB$mother_race)
View(natal)
# mother_race deleted
natalB<-natalB[,-(4)]
#Replacing na with the average mean of the column
natalB$drinks_per_week = ifelse(is.na(natalB$drinks_per_week), round(ave(natalB$drinks_per_week, FUN = function(x) mean(x, na.rm = TRUE ))), natalB$drinks_per_week)
natalB$born_alive_dead = ifelse(is.na(natalB$born_alive_dead), round(ave(natalB$born_alive_dead, FUN = function(x) mean(x, na.rm = TRUE ))), natalB$born_alive_dead)
natalB$born_alive_alive = ifelse(is.na(natalB$born_alive_alive), round(ave(natalB$born_alive_alive, FUN = function(x) mean(x, na.rm = TRUE ))), natalB$born_alive_alive)
natalB$born_dead = ifelse(is.na(natalB$born_dead), round(ave(natalB$born_dead, FUN = function(x) mean(x, na.rm = TRUE ))), natalB$born_dead)
natalB$cigarette_use = ifelse(is.na(natalB$cigarette_use), round(ave(natalB$cigarette_use, FUN = function(x) mean(x, na.rm = TRUE ))), natalB$cigarette_use)
natalB$alcohol_use = ifelse(is.na(natalB$alcohol_use), round(ave(natalB$alcohol_use, FUN = function(x) mean(x, na.rm = TRUE ))), natalB$alcohol_use)
natalB$cigarettes_per_day[is.na(natalB$cigarettes_per_day)] = 0
natalB$ever_born = ifelse(is.na(natalB$ever_born), round(ave(natalB$ever_born, FUN = function(x) mean(x, na.rm = TRUE ))), natalB$ever_born)
natalB$weight_gain_pounds = ifelse(is.na(natalB$weight_gain_pounds), round(ave(natalB$weight_gain_pounds, FUN = function(x) mean(x, na.rm = TRUE ))), natalB$weight_gain_pounds)
natalB$gestation_weeks = ifelse(is.na(natalB$gestation_weeks), round(ave(natalB$gestation_weeks, FUN = function(x) mean(x, na.rm = TRUE ))), natalB$gestation_weeks)
# This clear all the objects in your Global environment
rm(list = ls())
# This clear all the objects in your Global environment
rm(list = ls())
# clears the console area
cat("\014")
# Sets R random number to start at the same sequence
set.seed(1234)
DATASET_FILENAME  <- "natality_100k.csv"          # Name of input dataset file
DATASET_FILENAME_B <- "natality_10k.csv"
OUTPUT_FIELD      <- "weightpounds"          # Field name of the output class to predict
natal<-read.csv(DATASET_FILENAME_B)
natalB<-read.csv(DATASET_FILENAME)
View(natalB)
# Child_race deleted
natalB<-natalB[,-(4)]
# X deleted
natalB<-natalB[,-(1)]
# Source Year deleted
natalB<-natalB[,-(1)]
# father_race deleted
natalB<-natalB[,-(16)]
# record_weight deleted
natalB<-natalB[,-(17)]
# mother_race deleted
natalB<-natalB[,-(4)]
#Converting the true falso to 1 and 0
natalB[,c("cigarette_use")] <- as.integer(as.logical(natalB$cigarette_use))
natalB[,c("alcohol_use")] <- as.integer(as.logical(natalB$alcohol_use))
natalB[,c("is_male")] <- as.integer(as.logical(natalB$is_male))
natalB[na.omit(natalB), ]
natalB[complete.cases(natalB), ]
View(natalB)
natalB<-natalB[complete.cases(natalB), ]
# This clear all the objects in your Global environment
rm(list = ls())
# clears the console area
cat("\014")
# Sets R random number to start at the same sequence
set.seed(1234)
DATASET_FILENAME  <- "natality_500k.csv"          # Name of input dataset file
DATASET_FILENAME_B <- "natality_10k.csv"
OUTPUT_FIELD      <- "weightpounds"          # Field name of the output class to predict
natal<-read.csv(DATASET_FILENAME_B)
natalB<-read.csv(DATASET_FILENAME)
# Child_race deleted
natalB<-natalB[,-(4)]
# X deleted
natalB<-natalB[,-(1)]
# Source Year deleted
natalB<-natalB[,-(1)]
# father_race deleted
natalB<-natalB[,-(16)]
# record_weight deleted
natalB<-natalB[,-(17)]
# mother_race deleted
natalB<-natalB[,-(4)]
#Converting the true falso to 1 and 0
natalB[,c("cigarette_use")] <- as.integer(as.logical(natalB$cigarette_use))
natalB[,c("alcohol_use")] <- as.integer(as.logical(natalB$alcohol_use))
natalB[,c("is_male")] <- as.integer(as.logical(natalB$is_male))
natalB<-natalB[complete.cases(natalB), ]
View(natalB)
# This clear all the objects in your Global environment
rm(list = ls())
# clears the console area
cat("\014")
# Sets R random number to start at the same sequence
set.seed(1234)
DATASET_FILENAME  <- "natality_500k.csv"          # Name of input dataset file
DATASET_FILENAME_B <- "natality_10k.csv"
OUTPUT_FIELD      <- "weightpounds"          # Field name of the output class to predict
natal<-read.csv(DATASET_FILENAME_B)
natalB<-read.csv(DATASET_FILENAME)
# Child_race deleted
natalB<-natalB[,-(4)]
# X deleted
natalB<-natalB[,-(1)]
# Source Year deleted
natalB<-natalB[,-(1)]
# father_race deleted
natalB<-natalB[,-(16)]
# record_weight deleted
natalB<-natalB[,-(17)]
# mother_race deleted
natalB<-natalB[,-(4)]
#Converting the true falso to 1 and 0
natalB[,c("cigarette_use")] <- as.integer(as.logical(natalB$cigarette_use))
natalB[,c("alcohol_use")] <- as.integer(as.logical(natalB$alcohol_use))
natalB[,c("is_male")] <- as.integer(as.logical(natalB$is_male))
natalB$cigarette_use = ifelse(is.na(natalB$cigarette_use), round(ave(natalB$cigarette_use, FUN = function(x) mean(x, na.rm = TRUE ))), natalB$cigarette_use)
natalB$alcohol_use = ifelse(is.na(natalB$alcohol_use), round(ave(natalB$alcohol_use, FUN = function(x) mean(x, na.rm = TRUE ))), natalB$alcohol_use)
natalB$cigarettes_per_day[is.na(natalB$cigarettes_per_day)] = 0
natalB<-natalB[complete.cases(natalB), ]
View(natalB)
# This clear all the objects in your Global environment
rm(list = ls())
# clears the console area
cat("\014")
# Sets R random number to start at the same sequence
set.seed(1234)
DATASET_FILENAME  <- "natality_500k.csv"          # Name of input dataset file
DATASET_FILENAME_B <- "natality_10k.csv"
OUTPUT_FIELD      <- "weightpounds"          # Field name of the output class to predict
natal<-read.csv(DATASET_FILENAME_B)
natalB<-read.csv(DATASET_FILENAME)
# Child_race deleted
natalB<-natalB[,-(4)]
# X deleted
natalB<-natalB[,-(1)]
# Source Year deleted
natalB<-natalB[,-(1)]
# father_race deleted
natalB<-natalB[,-(16)]
# record_weight deleted
natalB<-natalB[,-(17)]
# mother_race deleted
natalB<-natalB[,-(4)]
names(natalB)
#Converting the true falso to 1 and 0
natalB[,c("cigarette_use")] <- as.integer(as.logical(natalB$cigarette_use))
natalB[,c("alcohol_use")] <- as.integer(as.logical(natalB$alcohol_use))
natalB[,c("is_male")] <- as.integer(as.logical(natalB$is_male))
natalB<-natalB[complete.cases(natalB), ]
View(natalB)
write.csv(natalB, "Natal_Result2")
View(natalB)
# This clear all the objects in your Global environment
rm(list = ls())
# clears the console area
cat("\014")
# Sets R random number to start at the same sequence
set.seed(1234)
myLibraries<-c("scatterplot3d", "caret")
library(pacman)
pacman::p_load(char=myLibraries, install = TRUE, character.only = TRUE)
#Load additional R script files provide for this lab
source("lab2functions.R")
natal<-read.csv("Natal_Result2")
natal<-natal[,-(1)]
# Randomise the entire dataset
natal<-natal[order(runif(nrow(natal))),]
names(natal)
training_records<-round(nrow(natal)*(70/100))
training_data<-natal[1:training_records,]
testing_data = natal[-(1:training_records),]
NscatterPlotError<-function(datasetTrain, datasetTest, outputName,predictorName) {
#Creates a "formula" and the trains model on TRAIN dataset
formular<-paste(outputName,"~",predictorName)
linearModel<-lm(formula=formular,data=datasetTrain)
# Extract predictor (input) values from TEST dataset into a data frame
predictorInput<-subset(datasetTest,select=predictorName)
# Get predictions from the model using the TEST dataset
y_predicted<-predict(linearModel, predictorInput)
#Extract the expected response (output) values from TEST dataset
# into a dataframe
y_actual<-datasetTest[,outputName]
# Calculate the metrics using functions in lab2functions.R
RMSE<-round(Nrmse(actual=y_actual,predicted=y_predicted),digits=2)
mae<-round(Nmae(actual=y_actual,predicted=y_predicted),digits=2)
r2<-round(Nr2(linearModel),digits=2)
error<-y_actual-y_predicted
#Create a data frame, so that we can sort these
# the input predictor (x)
# the expected value (actual_y)
#  and the residuals in the model
results<-data.frame(predictorInput,y_actual,error)
#order from lowest to highest the valexpected values
#for the ease of visualization
results<-results[order(y_actual),]
plot(results[,predictorName],
results$y_actual,
pch=4,
ylab=outputName,
xlab=predictorName,
main="Linear Regression Errors",
sub=paste("MAE=",mae,"RMSE=",RMSE," R2=",r2))
#Plot the linear model as a straight line
abline(linearModel,col = "blue", lwd=3)
# Plot vertical lines from the actual points to the predicted value,
# highlighting the error magnitude
suppressWarnings(arrows(results[,predictorName],
results$y_actual,
results[,predictorName],
results$y_actual-results$error,
length=0.05,angle=90,code=3,col="red"))
return(list(
MAE=mae,
RMSE=RMSE,
r2=r2))
}
results<-NscatterPlotError(datasetTrain=training_data, datasetTest=testing_data,
outputName="weight_pounds", predictorName="gestation_weeks")
# Try it with a diiferent predictor crim
results<-NscatterPlotError(datasetTrain=training_data, datasetTest=testing_data,
outputName="weight_pounds", predictorName="mother_age")
results<-NscatterPlotError(datasetTrain=training_data, datasetTest=testing_data,
outputName="weight_pounds", predictorName="weight_gain_pounds")
# Try it with a diiferent predictor crim
results<-NscatterPlotError(datasetTrain=training_data, datasetTest=testing_data,
outputName="weight_pounds", predictorName="cigarettes_per_day")
NplotAllErrors<-function(datasetTrain, datasetTest, outputName){
print("RESULTS")
y<- data.frame(matrix(ncol = 4, nrow = 0))
x<-c("Field","r2","RMSE","MAE")
colnames(y) <- x
for(i in 1:ncol(datasetTest)){
xname<-names(datasetTest) [i]
if(xname!="weight_pounds"){
results<-NscatterPlotError(datasetTrain=datasetTrain, datasetTest=datasetTest,
outputName=outputName, predictorName=xname)
print(paste("Field=",xname,
"r2",results$r2,
"RMSE",results$RMSE,
"MAE",results$MAE))
res<-data.frame(Field=xname,r2=results$r2,RMSE=results$RMSE,MAE=results$MAE)
y<-rbind(y,res)
}
}
print(y)
}
NplotAllErrors(datasetTrain=training_data, datasetTest=testing_data,outputName="weight_pounds")
DATASET_FILENAME_B <- "natality_10k.csv"
natal<-read.csv(DATASET_FILENAME_B)
View(natal)
View(results)
# This clear all the objects in your Global environment
rm(list = ls())
# clears the console area
cat("\014")
# Sets R random number to start at the same sequence
set.seed(1234)
DATASET_FILENAME  <- "natality_500k.csv"          # Name of input dataset file
DATASET_FILENAME_B <- "natality_10k.csv"
OUTPUT_FIELD      <- "weightpounds"          # Field name of the output class to predict
natal<-read.csv(DATASET_FILENAME_B)
natalB<-read.csv(DATASET_FILENAME)
# Child_race deleted
natalB<-natalB[,-(4)]
# X deleted
natalB<-natalB[,-(1)]
# Source Year deleted
natalB<-natalB[,-(1)]
# father_race deleted
natalB<-natalB[,-(16)]
# record_weight deleted
natalB<-natalB[,-(17)]
# mother_race deleted
natalB<-natalB[,-(4)]
natalB<-natalB[, -(6)]
names(natalB)
natalB<-natalB[, -(6)]
natalB<-natalB[, -(6)]
natalB<-natalB[, -(6)]
natalB<-natalB[, -(7)]
names(natalB)
natalB<-natalB[, -(7)]
natalB<-natalB[, -(7)]
natalB[,c("is_male")] <- as.integer(as.logical(natalB$is_male))
natalB<-natalB[complete.cases(natalB), ]
write.csv(natalB, "Natal_Result3")
DATASET_FILENAME  <- "Natal_Result3"          #Name of input dataset file
OUTPUT_FIELD      <- "weight_pounds"             # Field name of the output class to predict
# This clear all the objects in your Global environment
rm(list = ls())
# clears the console area
cat("\014")
DATASET_FILENAME  <- "Natal_Result3"          #Name of input dataset file
OUTPUT_FIELD      <- "weight_pounds"             # Field name of the output class to predict
HOLDOUT           <- 70                   # % split to create TRAIN dataset
CUTOFF_OUTLIER    <- 0.99                 # Confidence p-value for outlier detection
# negative = analyse but do not replace outliers
CUTOFF_DISCRETE   <- 5                    # Number of empty bins to determine discrete
CUTOFF_REDUNDANT  <- 0.95                 # Linear correlation coefficient cut-off
TYPE_DISCRETE     <- "DISCRETE"           # field is discrete (numeric)
TYPE_ORDINAL      <- "ORDINAL"            # field is continuous numeric
TYPE_SYMBOLIC     <- "SYMBOLIC"           # field is a string
TYPE_NUMERIC      <- "NUMERIC"            # field is initially a numeric
TYPE_IGNORE       <- "IGNORE"             # field is not encoded
MAX_LITERALS      <- 55                    # Maximum numner of 1-hot-encoding fields
PDF_FILENAME      <- "tree.pdf"           # Name of PDF with graphical tree diagram
RULES_FILENAME    <- "rules.txt"          # Name of text file with rules saved
RESULTS_FILENAME  <- "results.csv"        # Name of the CSV results file
NODE_LEVEL        <- 1                    # The number is the node level of the tree to print
BOOST             <- 20                   # Number of boosting iterations. 1=single model
FOREST_SIZE       <- 1000                 # Number of trees in the forest
SCALE_DATASET     <- TRUE                 # Set to true to scale dataset before ML stage
BASICNN_HIDDEN    <- 5                    # 10 hidden layer neurons
BASICNN_EPOCHS    <- 100                  # Maximum number of training epocs
DEEP_HIDDEN       <- c(5,5)               # Number of neurons in each layer
DEEP_STOPPING     <- 2                    # Number of times no improvement before stop
DEEP_TOLERANCE    <- 0.01                 # Error threshold
DEEP_ACTIVATION   <- "TanhWithDropout"    # Non-linear activation function
DEEP_REPRODUCABLE <- TRUE                 # Set to TRUE to test training is same for each run
MYLIBRARIES<-c("outliers",
"corrplot",
"MASS",
"formattable",
"stats",
"caret",
"PerformanceAnalytics",
"stringr",
"partykit",
"C50",
"randomForest",
"keras",
"h2o")
library(pacman)
pacman::p_load(char=MYLIBRARIES,install=TRUE,character.only=TRUE)
library(keras)
#Load additional R script files provide for this lab
source("4labFunctions.R")
source("lab4DataPrepNew.R")
randomForest<-function(train,test){
positionClassOutput<-which(names(train)==OUTPUT_FIELD)
train_inputs<-train[-positionClassOutput]
train_expected<-train[,positionClassOutput]
myTitle<-"Preprocessed Dataset. Random Forest= 1000 trees"
rf<-randomForest::randomForest(x=train_inputs,
factor(train_expected),
ntree=FOREST_SIZE,
mtry=sqrt(ncol(train_inputs)))
print(summary(rf))
# Use the created decision tree with the test dataset
# to determine best classification threshold & calculate metrics
measures<-getTreeClassifications(myTree = rf,
testDataset = test,
title=myTitle)
return(measures)
}
fullDT<-function(train,test,boost=1,plot=TRUE){
positionClassOutput<-which(names(train)==OUTPUT_FIELD)
# train data: dataframe with the input fields
train_inputs<-train[-positionClassOutput]
# train data: vector with the expedcted output
train_expected<-train[,positionClassOutput]
# ************************************************
# Create a standard Decision Tree using the C5.0 algorithm
# Uses library C50
# Outputs the tree in the format of rules
myTitle<-"Preprocessed Dataset. DT C5.0"
if (boost>1)
myTitle<-paste(myTitle,"BOOSTED=",boost)
print(myTitle)
tree<-C50::C5.0(x=train_inputs,
factor(train_expected),
rules=TRUE,
trials=BOOST)
print(summary(tree))
# Use the created decision tree with the test dataset
# to determine best classification threshold & calculate metrics
measures<-getTreeClassifications(myTree = tree,
testDataset = test,
title=myTitle)
if (plot==TRUE){
print(summary(tree))
# Get importance of the input fields
importance<-C50::C5imp(tree, metric = "usage")
names(importance)<-"Strength"
importance<-importance[order(importance$Strength, decreasing = TRUE),,drop=FALSE]
print(formattable::formattable(importance))
# Plot the importance fields
barplot(t(importance),las=2,
border = 0, cex.names =0.7,
main=myTitle)
dftreerules<-NDT5RuleOutput(tree)
print(formattable::formattable(dftreerules))
print("Plot decision tree to file called tree.pdf")
Global_train_inputs<<-train_inputs
Global_train_expected<<-train_expected
# :: is used to specify a function within the named package to avoid confusion
tree<-C50::C5.0(x=Global_train_inputs,
factor(Global_train_expected),
trials=boost)
# ::: is used to directly access a member of a package that is internal
graphtree<-C50:::as.party.C5.0(tree)
# The plot is large - so print to a big PDF file
pdf(PDF_FILENAME, width=100, height=50, paper="special", onefile=F)
# The number is the node level of the tree to print
plot(graphtree[NODE_LEVEL])
#This closes the PDF file
dev.off()
}
return(measures)
}
simpleDT<-function(train,test,plot=TRUE){
positionClassOutput<-which(names(train) == OUTPUT_FIELD)
x<-train[-positionClassOutput]
y<-factor(train[,positionClassOutput])
tree <- C50::C5.0(x, y, trials=1, rules=TRUE)
measures<-getTreeClassifications(tree, test, title = "Orginal Dataset. DT C5.0")
return(measures)
}
getTreeClassifications<-function(myTree,testDataset,title,classLabel=1, plot=TRUE){
positionClassOutput<-which(names(testDataset) == OUTPUT_FIELD)
x<-testDataset[-positionClassOutput]
test_inputs<-data.frame(x)
testPredictedClassProbs<-predict(myTree, test_inputs, type="prob")
# Get the column index with the class label
classIndex<-which(as.numeric(colnames(testPredictedClassProbs)) == classLabel)
# Get the probabilities for classifying the good loans
test_predictedProbs<-testPredictedClassProbs[,classIndex]
#test data: vector with just the expected output class
test_expected<-testDataset[,positionClassOutput]
measures<-NdetermineThreshold(test_predictedProbs,test_expected,plot=plot,title=title)
return(measures)
}
mlpNeural<-function(train,test, plot = TRUE){
myTitle<-paste("Preprocessed Dataset. MLP. Hidden=",BASICNN_HIDDEN,sep="")
print(myTitle)
mlp_classifier<-N_MLP_TrainClassifier(train=train, fieldNameOutput=OUTPUT_FIELD,
hidden=BASICNN_HIDDEN,
plot=plot)
measures<-N_evaluate_MLP(test=test, fieldNameOutput=OUTPUT_FIELD,
mlp_classifier=mlp_classifier,
plot=plot,
myTitle=myTitle)
return(measures)
}
metricsToRealWorld<-function(dataset, measures, natural){
badloan<-0
goodloan<-0
positionClassOutput=which(names(dataset) == OUTPUT_FIELD)
x<-dataset[positionClassOutput]
inputs<-data.frame(x)
for(field in 1:(nrow(inputs))){
if (inputs[field,1] == 0) {
badloan<-badloan + 1
}else {
goodloan<-goodloan + 1
}
}
classBalance<-badloan/goodloan
print(classBalance)
print(paste("Class balance, bad:good=", round(classBalance, digits = 2)))
}
deepNeural<-function(train, test, plot = TRUE){
myTitle<-"Preprocessed Dataset. Deep NN"
N_DEEP_Initialise()
deep_classifier<-N_DEEP_TrainClassifier(train=train,
fieldNameOutput=OUTPUT_FIELD,
hidden=DEEP_HIDDEN,
stopping_rounds=DEEP_STOPPING,
stopping_tolerance=DEEP_TOLERANCE,
activation=DEEP_ACTIVATION,
reproducible=DEEP_REPRODUCABLE)
# Evaluate the deep NN as we have done previously
measures<-N_EVALUATE_DeepNeural(test=test,
fieldNameOutput=OUTPUT_FIELD,
deep=deep_classifier,
plot=plot,
myTitle = myTitle)
if (plot==TRUE){
# ************************************************
# TELL ME SOMETHING INTERESTING...
summary(deep_classifier)
plot(deep_classifier) # plots the scoring history
# variable importance from the deep neural network
importance = as.data.frame(h2o::h2o.varimp(deep_classifier))
row.names(importance)<-importance$variable
importanceScaled<-subset(importance, select=scaled_importance)*100
colnames(importanceScaled)<-"Strength"
barplot(t(importanceScaled),las=2, border = 0,
cex.names =0.7,
main=myTitle)
print(formattable::formattable(data.frame(importanceScaled)))
}
# ************************************************
return(measures)
}
loans <- read.csv(DATASET_FILENAME)
loans<-loans[,-(1)]
original<-NConvertClass(loans)
original<-NPREPROCESSING_splitdataset(original)
measures<-simpleDT(original$train, original$test)
measures<-fullDT(original$train, original$test)
dataset<-NPREPROCESSING_dataset(loans, scaleFlag = TRUE)
splitData<-NPREPROCESSING_splitdataset(loans)
dataset<-NPREPROCESSING_dataset(loans, scaleFlag = TRUE)
